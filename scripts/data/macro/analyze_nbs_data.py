#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
NBSæ•°æ®åˆ†æè„šæœ¬

æ·±å…¥åˆ†æå›½å®¶ç»Ÿè®¡å±€åŸå§‹æ•°æ®ï¼Œå‘ç°å·¥ä¸šå“äº§é‡ã€æŠ•èµ„ã€ä»·æ ¼çš„å˜åŒ–è§„å¾‹
"""

import pandas as pd
import json
import os
from datetime import datetime
import numpy as np

from scripts.data.macro.paths import MACRO_DIR

class NBSDataAnalyzer:
    """NBSæ•°æ®åˆ†æå™¨"""
    
    def __init__(self, data_dir: str = None):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        
        Args:
            data_dir: æ•°æ®ç›®å½•
        """
        self.data_dir = data_dir or str(MACRO_DIR)
    
    def parse_nbs_json(self, json_file: str) -> pd.DataFrame:
        """è§£æNBS JSONæ•°æ®"""
        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        if 'returndata' not in data:
            return pd.DataFrame()
        
        returndata = data['returndata']
        
        # è·å–ç»´åº¦èŠ‚ç‚¹
        zb_nodes = []
        sj_nodes = []
        
        for node in returndata.get('wdnodes', []):
            if node['wdcode'] == 'zb':
                zb_nodes = node['nodes']
            elif node['wdcode'] == 'sj':
                sj_nodes = node['nodes']
        
        # åˆ›å»ºæ˜ å°„
        zb_code_to_name = {node['code']: node['name'] for node in zb_nodes}
        zb_code_to_unit = {node['code']: node.get('unit', '') for node in zb_nodes}
        sj_code_to_name = {node['code']: node['name'] for node in sj_nodes}
        
        # è§£ææ•°æ®èŠ‚ç‚¹
        records = []
        for datanode in returndata.get('datanodes', []):
            if not datanode['data']['hasdata']:
                continue
            
            wds = datanode['wds']
            zb_code = None
            sj_code = None
            
            for wd in wds:
                if wd['wdcode'] == 'zb':
                    zb_code = wd['valuecode']
                elif wd['wdcode'] == 'sj':
                    sj_code = wd['valuecode']
            
            if zb_code and sj_code:
                value = datanode['data']['data']
                records.append({
                    'product_code': zb_code,
                    'product_name': zb_code_to_name.get(zb_code, ''),
                    'product_unit': zb_code_to_unit.get(zb_code, ''),
                    'time_code': sj_code,
                    'time_name': sj_code_to_name.get(sj_code, ''),
                    'value': value
                })
        
        df = pd.DataFrame(records)
        
        # è½¬æ¢æ—¶é—´
        if len(df) > 0:
            df['date'] = pd.to_datetime(df['time_code'].astype(str), format='%Y%m')
        
        return df
    
    def analyze_output_trends(self, df: pd.DataFrame) -> dict:
        """
        åˆ†æå·¥ä¸šå“äº§é‡è¶‹åŠ¿
        
        Args:
            df: å·¥ä¸šå“äº§é‡æ•°æ®
        
        Returns:
            dict: åˆ†æç»“æœ
        """
        if len(df) == 0:
            return {}
        
        print("\n" + "=" * 80)
        print("å·¥ä¸šå“äº§é‡è¶‹åŠ¿åˆ†æ")
        print("=" * 80)
        
        results = {}
        
        # 1. æ•°æ®è¦†ç›–æƒ…å†µ
        print(f"\n1. æ•°æ®è¦†ç›–æƒ…å†µ")
        print(f"   æ€»è®°å½•æ•°: {len(df)}")
        print(f"   äº§å“ç§ç±»: {df['product_code'].nunique()}")
        print(f"   æ—¶é—´èŒƒå›´: {df['date'].min()} ~ {df['date'].max()}")
        print(f"   æ—¶é—´è·¨åº¦: {(df['date'].max() - df['date'].min()).days / 365.25:.1f}å¹´")
        
        # 2. æŒ‰äº§å“åˆ†æ
        print(f"\n2. å„äº§å“æ•°æ®è¦†ç›–")
        product_coverage = df.groupby('product_code').agg({
            'product_name': 'first',
            'product_unit': 'first',
            'value': 'count',
            'date': ['min', 'max']
        }).reset_index()
        product_coverage.columns = ['product_code', 'product_name', 'unit', 'count', 'start_date', 'end_date']
        product_coverage = product_coverage.sort_values('count', ascending=False)
        
        print(f"   TOP 10 äº§å“:")
        for i, row in product_coverage.head(10).iterrows():
            print(f"     {i+1}. {row['product_name']} ({row['product_code']})")
            print(f"        æ•°æ®ç‚¹: {row['count']}ä¸ª, å•ä½: {row['unit']}")
            print(f"        æ—¶é—´: {row['start_date'].strftime('%Y-%m')} ~ {row['end_date'].strftime('%Y-%m')}")
        
        # 3. è®¡ç®—å¢é•¿ç‡
        df_sorted = df.sort_values(['product_code', 'date']).reset_index(drop=True)
        df_sorted['yoy'] = df_sorted.groupby('product_code')['value'].pct_change(periods=12) * 100
        df_sorted['mom'] = df_sorted.groupby('product_code')['value'].pct_change() * 100
        
        # 4. æœ€è¿‘3ä¸ªæœˆå¢é•¿ç‡æ’å
        print(f"\n3. æœ€è¿‘3ä¸ªæœˆç¯æ¯”å¢é•¿ç‡æ’å")
        recent_date = df_sorted['date'].max()
        recent_3m = df_sorted[df_sorted['date'] >= recent_date - pd.Timedelta(days=90)]
        
        recent_growth = recent_3m.groupby('product_code').agg({
            'product_name': 'first',
            'mom': ['mean', 'last']
        }).reset_index()
        recent_growth.columns = ['product_code', 'product_name', 'mom_avg_3m', 'mom_last']
        recent_growth = recent_growth.dropna(subset=['mom_avg_3m'])
        recent_growth = recent_growth.sort_values('mom_avg_3m', ascending=False)
        
        print(f"   ç¯æ¯”å¢é•¿æœ€å¿«TOP 10:")
        for i, row in recent_growth.head(10).iterrows():
            print(f"     {i+1}. {row['product_name']}: +{row['mom_avg_3m']:.2f}% (æœ€æ–°: {row['mom_last']:.2f}%)")
        
        print(f"\n   ç¯æ¯”ä¸‹é™æœ€å¿«TOP 10:")
        for i, row in recent_growth.tail(10).iterrows():
            print(f"     {i+1}. {row['product_name']}: {row['mom_avg_3m']:.2f}% (æœ€æ–°: {row['mom_last']:.2f}%)")
        
        # 5. åŒæ¯”å¢é•¿ç‡æ’å
        print(f"\n4. æœ€è¿‘12ä¸ªæœˆåŒæ¯”å¢é•¿ç‡æ’å")
        recent_12m = df_sorted[df_sorted['date'] >= recent_date - pd.Timedelta(days=365)]
        
        recent_yoy = recent_12m.groupby('product_code').agg({
            'product_name': 'first',
            'yoy': ['mean', 'last']
        }).reset_index()
        recent_yoy.columns = ['product_code', 'product_name', 'yoy_avg_12m', 'yoy_last']
        recent_yoy = recent_yoy.dropna(subset=['yoy_avg_12m'])
        recent_yoy = recent_yoy.sort_values('yoy_avg_12m', ascending=False)
        
        print(f"   åŒæ¯”å¢é•¿æœ€å¿«TOP 10:")
        for i, row in recent_yoy.head(10).iterrows():
            print(f"     {i+1}. {row['product_name']}: +{row['yoy_avg_12m']:.2f}% (æœ€æ–°: {row['yoy_last']:.2f}%)")
        
        # 6. æ‹ç‚¹æ£€æµ‹ï¼ˆè¿ç»­2ä¸ªæœˆç”±è´Ÿè½¬æ­£æˆ–ç”±æ­£è½¬è´Ÿï¼‰
        print(f"\n5. å¢é•¿ç‡æ‹ç‚¹æ£€æµ‹")
        for product_code in df_sorted['product_code'].unique():
            product_data = df_sorted[df_sorted['product_code'] == product_code].tail(6)  # æœ€è¿‘6ä¸ªæœˆ
            
            if len(product_data) < 4:
                continue
            
            # æ£€æŸ¥ç¯æ¯”æ‹ç‚¹
            mom_changes = product_data['mom'].diff()
            
            # æ£€æµ‹ç”±è´Ÿè½¬æ­£
            if (mom_changes.iloc[-2] > 0 and 
                product_data['mom'].iloc[-3] < 0 and 
                product_data['mom'].iloc[-1] > 0):
                print(f"   âš ï¸  {product_data['product_name'].iloc[-1]}: ç¯æ¯”ç”±è´Ÿè½¬æ­£ï¼")
                print(f"      è¿‘3ä¸ªæœˆç¯æ¯”: {product_data['mom'].iloc[-3]:.2f}% â†’ {product_data['mom'].iloc[-2]:.2f}% â†’ {product_data['mom'].iloc[-1]:.2f}%")
            
            # æ£€æµ‹ç”±æ­£è½¬è´Ÿ
            if (mom_changes.iloc[-2] < 0 and 
                product_data['mom'].iloc[-3] > 0 and 
                product_data['mom'].iloc[-1] < 0):
                print(f"   âš ï¸  {product_data['product_name'].iloc[-1]}: ç¯æ¯”ç”±æ­£è½¬è´Ÿï¼")
                print(f"      è¿‘3ä¸ªæœˆç¯æ¯”: {product_data['mom'].iloc[-3]:.2f}% â†’ {product_data['mom'].iloc[-2]:.2f}% â†’ {product_data['mom'].iloc[-1]:.2f}%")
        
        results = {
            'product_coverage': product_coverage,
            'recent_growth': recent_growth,
            'recent_yoy': recent_yoy,
            'df_with_metrics': df_sorted
        }
        
        return results
    
    def analyze_fai_trends(self, df: pd.DataFrame) -> dict:
        """
        åˆ†æå›ºå®šèµ„äº§æŠ•èµ„è¶‹åŠ¿
        
        Args:
            df: å›ºå®šèµ„äº§æŠ•èµ„æ•°æ®
        
        Returns:
            dict: åˆ†æç»“æœ
        """
        if len(df) == 0:
            return {}
        
        print("\n" + "=" * 80)
        print("å›ºå®šèµ„äº§æŠ•èµ„è¶‹åŠ¿åˆ†æ")
        print("=" * 80)
        
        # 1. æ•°æ®è¦†ç›–æƒ…å†µ
        print(f"\n1. æ•°æ®è¦†ç›–æƒ…å†µ")
        print(f"   æ€»è®°å½•æ•°: {len(df)}")
        print(f"   æŠ•èµ„é¢†åŸŸ: {df['product_code'].nunique()}")
        print(f"   æ—¶é—´èŒƒå›´: {df['date'].min()} ~ {df['date'].max()}")
        
        # 2. æŒ‰æŠ•èµ„é¢†åŸŸåˆ†æ
        print(f"\n2. å„æŠ•èµ„é¢†åŸŸæ•°æ®è¦†ç›–")
        fai_coverage = df.groupby('product_code').agg({
            'product_name': 'first',
            'product_unit': 'first',
            'value': 'count',
            'date': ['min', 'max']
        }).reset_index()
        fai_coverage.columns = ['product_code', 'product_name', 'unit', 'count', 'start_date', 'end_date']
        fai_coverage = fai_coverage.sort_values('count', ascending=False)
        
        print(f"   TOP 15 æŠ•èµ„é¢†åŸŸ:")
        for i, row in fai_coverage.head(15).iterrows():
            print(f"     {i+1}. {row['product_name']} ({row['product_code']})")
            print(f"        æ•°æ®ç‚¹: {row['count']}ä¸ª, å•ä½: {row['unit']}")
        
        # 3. è®¡ç®—å¢é•¿ç‡
        df_sorted = df.sort_values(['product_code', 'date']).reset_index(drop=True)
        df_sorted['yoy'] = df_sorted.groupby('product_code')['value'].pct_change(periods=12) * 100
        df_sorted['mom'] = df_sorted.groupby('product_code')['value'].pct_change() * 100
        
        # 4. æœ€è¿‘æŠ•èµ„å¢é€Ÿ
        print(f"\n3. æœ€è¿‘æŠ•èµ„å¢é€Ÿåˆ†æ")
        recent_date = df_sorted['date'].max()
        recent_6m = df_sorted[df_sorted['date'] >= recent_date - pd.Timedelta(days=180)]
        
        recent_fai = recent_6m.groupby('product_code').agg({
            'product_name': 'first',
            'yoy': 'last',
            'mom': 'last'
        }).reset_index()
        recent_fai = recent_fai.dropna(subset=['yoy', 'mom'])
        recent_fai = recent_fai.sort_values('yoy', ascending=False)
        
        print(f"   åŒæ¯”å¢é€Ÿæœ€å¿«TOP 10:")
        for i, row in recent_fai.head(10).iterrows():
            print(f"     {i+1}. {row['product_name']}: åŒæ¯”+{row['yoy']:.2f}%, ç¯æ¯”+{row['mom']:.2f}%")
        
        # 5. æŠ•èµ„æ‰©å¼ ä¿¡å·ï¼ˆè¿ç»­3ä¸ªæœˆæ­£å¢é•¿ï¼‰
        print(f"\n4. æŠ•èµ„æ‰©å¼ ä¿¡å·æ£€æµ‹")
        for product_code in df_sorted['product_code'].unique():
            product_data = df_sorted[df_sorted['product_code'] == product_code].tail(6)
            
            if len(product_data) < 3:
                continue
            
            # æ£€æŸ¥æ˜¯å¦è¿ç»­3ä¸ªæœˆæ­£å¢é•¿
            recent_mom = product_data['mom'].tail(3)
            if (recent_mom > 0).all():
                print(f"   ğŸš€ {product_data['product_name'].iloc[-1]}: è¿ç»­3ä¸ªæœˆæŠ•èµ„æ‰©å¼ ï¼")
                print(f"      è¿‘3ä¸ªæœˆç¯æ¯”: {recent_mom.iloc[0]:.2f}% â†’ {recent_mom.iloc[1]:.2f}% â†’ {recent_mom.iloc[2]:.2f}%")
        
        return {'df_with_metrics': df_sorted, 'recent_fai': recent_fai}
    
    def analyze_price_trends(self, df: pd.DataFrame) -> dict:
        """
        åˆ†æä»·æ ¼æŒ‡æ•°è¶‹åŠ¿
        
        Args:
            df: ä»·æ ¼æŒ‡æ•°æ•°æ®
        
        Returns:
            dict: åˆ†æç»“æœ
        """
        if len(df) == 0:
            return {}
        
        print("\n" + "=" * 80)
        print("ä»·æ ¼æŒ‡æ•°è¶‹åŠ¿åˆ†æ")
        print("=" * 80)
        
        # 1. æ•°æ®è¦†ç›–æƒ…å†µ
        print(f"\n1. æ•°æ®è¦†ç›–æƒ…å†µ")
        print(f"   æ€»è®°å½•æ•°: {len(df)}")
        print(f"   ä»·æ ¼ç§ç±»: {df['product_code'].nunique()}")
        print(f"   æ—¶é—´èŒƒå›´: {df['date'].min()} ~ {df['date'].max()}")
        
        # 2. æŒ‰ä»·æ ¼ç§ç±»åˆ†æ
        print(f"\n2. å„ä»·æ ¼ç§ç±»æ•°æ®è¦†ç›–")
        price_coverage = df.groupby('product_code').agg({
            'product_name': 'first',
            'value': 'count',
            'date': ['min', 'max']
        }).reset_index()
        price_coverage.columns = ['product_code', 'product_name', 'count', 'start_date', 'end_date']
        price_coverage = price_coverage.sort_values('count', ascending=False)
        
        print(f"   TOP 15 ä»·æ ¼ç§ç±»:")
        for i, row in price_coverage.head(15).iterrows():
            print(f"     {i+1}. {row['product_name']}")
            print(f"        æ•°æ®ç‚¹: {row['count']}ä¸ª")
        
        # 3. è½¬æ¢ä¸ºå¢é•¿ç‡ï¼ˆä»·æ ¼æŒ‡æ•°åŸºæ•°æ˜¯100ï¼‰
        df_sorted = df.sort_values(['product_code', 'date']).reset_index(drop=True)
        df_sorted['yoy'] = df_sorted.groupby('product_code')['value'].pct_change(periods=12) * 100
        df_sorted['mom'] = df_sorted.groupby('product_code')['value'].pct_change() * 100
        
        # 4. é€šèƒ€/é€šç¼©åˆ†æ
        print(f"\n3. é€šèƒ€/é€šç¼©åˆ†æ")
        recent_date = df_sorted['date'].max()
        recent_6m = df_sorted[df_sorted['date'] >= recent_date - pd.Timedelta(days=180)]
        
        recent_price = recent_6m.groupby('product_code').agg({
            'product_name': 'first',
            'value': 'last',
            'yoy': 'last',
            'mom': 'last'
        }).reset_index()
        recent_price = recent_price.dropna(subset=['yoy'])
        
        # é€šç¼©ï¼ˆåŒæ¯”<0ï¼‰
        deflation = recent_price[recent_price['yoy'] < 0].sort_values('yoy')
        print(f"   é€šç¼©ï¼ˆåŒæ¯”<0ï¼‰é¢†åŸŸï¼ˆæŒ‰ä¸¥é‡ç¨‹åº¦æ’åºï¼‰:")
        for i, row in deflation.head(10).iterrows():
            print(f"     {i+1}. {row['product_name']}: åŒæ¯”{row['yoy']:.2f}%, æŒ‡æ•°{row['value']:.1f}")
        
        # é€šèƒ€ï¼ˆåŒæ¯”>0ï¼‰
        inflation = recent_price[recent_price['yoy'] > 0].sort_values('yoy', ascending=False)
        print(f"\n   é€šèƒ€ï¼ˆåŒæ¯”>0ï¼‰é¢†åŸŸï¼ˆæŒ‰ç¨‹åº¦æ’åºï¼‰:")
        for i, row in inflation.head(10).iterrows():
            print(f"     {i+1}. {row['product_name']}: åŒæ¯”+{row['yoy']:.2f}%, æŒ‡æ•°{row['value']:.1f}")
        
        # 5. ä»·æ ¼æ‹ç‚¹æ£€æµ‹
        print(f"\n4. ä»·æ ¼æ‹ç‚¹æ£€æµ‹")
        for product_code in df_sorted['product_code'].unique():
            product_data = df_sorted[df_sorted['product_code'] == product_code].tail(6)
            
            if len(product_data) < 3:
                continue
            
            # æ£€æŸ¥ç”±é€šç¼©è½¬é€šèƒ€
            if (product_data['yoy'].iloc[-3] < 0 and 
                product_data['yoy'].iloc[-2] > 0 and 
                product_data['yoy'].iloc[-1] > 0):
                print(f"   ğŸ“ˆ {product_data['product_name'].iloc[-1]}: ç”±é€šç¼©è½¬é€šèƒ€ï¼")
                print(f"      è¿‘3ä¸ªæœˆåŒæ¯”: {product_data['yoy'].iloc[-3]:.2f}% â†’ {product_data['yoy'].iloc[-2]:.2f}% â†’ {product_data['yoy'].iloc[-1]:.2f}%")
            
            # æ£€æŸ¥ç”±é€šèƒ€è½¬é€šç¼©
            if (product_data['yoy'].iloc[-3] > 0 and 
                product_data['yoy'].iloc[-2] < 0 and 
                product_data['yoy'].iloc[-1] < 0):
                print(f"   ğŸ“‰ {product_data['product_name'].iloc[-1]}: ç”±é€šèƒ€è½¬é€šç¼©ï¼")
                print(f"      è¿‘3ä¸ªæœˆåŒæ¯”: {product_data['yoy'].iloc[-3]:.2f}% â†’ {product_data['yoy'].iloc[-2]:.2f}% â†’ {product_data['yoy'].iloc[-1]:.2f}%")
        
        return {'df_with_metrics': df_sorted, 'recent_price': recent_price}
    
    def comprehensive_analysis(self):
        """ç»¼åˆåˆ†ææ‰€æœ‰NBSæ•°æ®"""
        print("=" * 80)
        print("NBSæ•°æ®ç»¼åˆåˆ†æ")
        print("=" * 80)
        
        results = {}
        
        # 1. åˆ†æå·¥ä¸šå“äº§é‡
        output_file = os.path.join(self.data_dir, 'A020901_å·¥ä¸šå“äº§é‡.json')
        if os.path.exists(output_file):
            output_df = self.parse_nbs_json(output_file)
            if len(output_df) > 0:
                results['output'] = self.analyze_output_trends(output_df)
        
        # 2. åˆ†æå›ºå®šèµ„äº§æŠ•èµ„
        fai_file = os.path.join(self.data_dir, 'A0403_å›ºå®šèµ„äº§æŠ•èµ„.json')
        if os.path.exists(fai_file):
            fai_df = self.parse_nbs_json(fai_file)
            if len(fai_df) > 0:
                results['fai'] = self.analyze_fai_trends(fai_df)
        
        # 3. åˆ†æä»·æ ¼æŒ‡æ•°
        price_file = os.path.join(self.data_dir, 'A010D02_ä»·æ ¼æŒ‡æ•°.json')
        if os.path.exists(price_file):
            price_df = self.parse_nbs_json(price_file)
            if len(price_df) > 0:
                results['price'] = self.analyze_price_trends(price_df)
        
        # 4. ç»¼åˆå‘ç°
        print("\n" + "=" * 80)
        print("ç»¼åˆå‘ç°æ€»ç»“")
        print("=" * 80)
        
        print("\nğŸ“Š NBSæ•°æ®åˆ†æç»“è®º:")
        print("1. å·¥ä¸šå“äº§é‡æ•°æ®ï¼šåæ˜ å®ä½“ç»æµæ´»è·ƒåº¦")
        print("2. å›ºå®šèµ„äº§æŠ•èµ„æ•°æ®ï¼šåæ˜ èµ„æœ¬å¼€æ”¯å’Œäº§èƒ½æ‰©å¼ æ„æ„¿") 
        print("3. ä»·æ ¼æŒ‡æ•°æ•°æ®ï¼šåæ˜ é€šèƒ€/é€šç¼©å‹åŠ›")
        print("\nğŸ’¡ æŠ•èµ„å¯ç¤º:")
        print("- äº§é‡+æŠ•èµ„åŒå¢é•¿ï¼šè¡Œä¸šæ™¯æ°”åº¦ä¸Šè¡Œ")
        print("- äº§é‡å¢é•¿+ä»·æ ¼ä¸Šå‡ï¼šé‡ä»·é½å‡ï¼Œæœ€ä½³æŠ•èµ„æœºä¼š")
        print("- ä»·æ ¼ç”±è´Ÿè½¬æ­£ï¼šé€šç¼©ç¼“è§£ï¼Œå…³æ³¨æ‹ç‚¹æœºä¼š")
        print("- æŠ•èµ„è¿ç»­æ‰©å¼ ï¼šäº§èƒ½é‡Šæ”¾ï¼Œå…³æ³¨ä¾›éœ€å˜åŒ–")
        
        return results


def main():
    """ä¸»å‡½æ•°"""
    analyzer = NBSDataAnalyzer()
    results = analyzer.comprehensive_analysis()
    
    # ä¿å­˜è¯¦ç»†åˆ†æç»“æœ
    output_dir = 'data/processed'
    os.makedirs(output_dir, exist_ok=True)
    
    for data_type, data_dict in results.items():
        if 'df_with_metrics' in data_dict:
            output_file = os.path.join(output_dir, f'nbs_{data_type}_analysis.parquet')
            data_dict['df_with_metrics'].to_parquet(output_file, index=False)
            print(f"\n{data_type}åˆ†æç»“æœå·²ä¿å­˜åˆ°: {output_file}")


if __name__ == '__main__':
    main()
